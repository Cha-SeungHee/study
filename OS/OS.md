## 메모리 종류
- 레지스터, 캐시, 메인 메모리, 하드 디스크  
- 레지스터, 캐시: CPU 내부에 존재 -> 아주 빠르게 접근 가능  
- 메모리: CPU 외부에 존재 -> 레지스터와 캐시에 비해 접근 속도가 느림  
- 하드디스크: 하드 디스크의 데이터를 메모리로 이동 -> 메모리에 접근 (가장 느림)  

## 캐시란 무엇인가요
- CPU의 처리속도와 주기억장치의 접근 속도 차이를 줄이기 위해 사용하는 메모리  
- 프로세서가 매번 메인 메모리에 접근해 데이터를 받아오면 시간이 오래 걸리기 때문에 캐시에 자주 사용하는 데이터를 담아두고, 필요시 캐시에 접근하도록해 처리속도 상승  
- 빠르지만 가격이 비쌈  
- 캐시의 성능은 CPU가 이후에 참조할 정보가 어느 정도 들어있느냐에 따라 좌우 -> 적중률 (Cache Hit Rate)  
- 적중률을 높히기 위해 지역성(Locality)의 원리를 사용  
- 시간 지역성: 최근에 참조된 주소의 내용은 곧 다시 참조된다 (예시: for문, while문)  
- 공간 지역성: 현재 참조된 주소와 인접한 주소의 내용이 앞으로 참조될 가능성이 높다 (예시: 배열의 연속적 데이터)

#### 캐시 구조 (중요 x)
- 캐시는 반응속도가 빠른 SRAM  
- 주소가 키로 주어지면 O(1)의 시간복잡도로 해당 공간에 접근할 수 있는 하드웨어로 구현한 해시 테이블 
(메인메모리로 주로 사용되는 DRAM도 동일하나 SRAM이 더 빠름)  
- 블록으로 구성되며 블록 내에 데이터 존재. 블록의 크기가 캐시의 크기를 결정  
- 주소값의 일부를 키로 사용 (일부는 index, 일부는 tag)  
- Index: 블록을 구분하기 위해 사용 / Tag: 블록 내 구분  
- 데이터 배열과 태그 배열 존재
- 각 Index에 해당하는 tag 배열이 존재하고 해당 tag 배열의 유효 비트가 1이면 tag 배열의 값을 확인. 주소의 태그와 값이 동일하면 hit  

#### Tag overhead
- 태그 배열이 추가되면서 더 많은 공간 필요  
- 태그 배열에 접근해 히트 확인 후 데이터 배열에 접근해 데이터를 가져오면 hit latency 증가하기에 두 과정을 병렬적으로 실행  
- Hit latency는 줄어드나 miss인 경우 리소스 낭비   

#### Associate Cache
- 서로 다른 두 주소가 같은 인덱스를 가지면 충돌이 발생하고 교체 정책에 따라 블록을 교체  
- 충돌이 발생할 때마다 캐시 내용을 바꾸면 많은 미스 발생할 수 있고 비효율적  
- 태그 배열과 데이터 배열을 여러 개 만드는 방식으로 개선 가능  
- 인덱스가 가리키는 블록의 개수에 따라 다음과 같이 분류  

  1) Direct mapped
  - 인덱스가 가리키는 공간이 하나인 경우. 여러 개의 주소가 캐시 메모리의 한 주소에 대응되는 N:1 방식  
  - 처리가 빠르지만 충돌이 잦다  
  
  2) Fully associative
  - 인덱스가 모든 공간을 가리키는 경우. 충돌이 적지만 모든 블록을 탐색해야 해서 속도가 느림   
  - 특별한 알고리즘 없이 비어있는 주소에 저장  
  - 찾을 때 모든 블럭을 순회해야하는 단점  
  
  3) Set associative
  - 인덱스가 가리키는 공간이 두 개 이상인 경우. N-way set associative 캐시라고 불린다  
  - 2-way set associatived의 경우 데이터가 캐싱되어 있는지 확인하려면 하나의 블록이 아닌 두개의 블록을 모두 확인해야 한다  

https://parksb.github.io/article/29.html  

## 프로세스와 스레드 차이에 대해 설명해주세요
#### 프로세스
- 프로세스는 실행 중인 프로그램으로 운영체제로부터 시스템 자원을 할당받는 작업의 단위  
- 프로세스마다 최소 하나의 스레드를 가지고 있으며, 각각 별도의 주소공간을 할당
- 프로세스 내에는 code, data, heap, stack 영역이 존재

#### 프로세스 제어 블록 (Process Control Block, PCB)
- 프로세스에 대한 정보를 저장하고 있는 OS의 자료구조  
- OS는 프로세스의 생성과 동시에 고유한 PCB 생성  

- 프로세스 식별자  
- 프로세스 상태    
- 프로그램 카운터   
- CPU 레지스터  
- CPU 스케쥴링 정보 (우선 순위 등)  
- 메모리 관리 정보 (페이지 테이블 또는 세그먼트 테이블 등)  

#### 스레드
- 스레드는 프로세스 내에서 실행 단위   
- 스레드는 stack만 따로 할당받고 나머지 영역은 다른 스레드와 공유  
- Stack은 함수 인자, 되돌아갈 주소값, 함수내 지역변수 등이 저장되고 독립적인 실행 흐름에서는 독립적인 함수 호출을 위한 스택이 필요
- 멀티스레딩: 하나의 프로세스를 다수의 실행 단위로 구분하여 자원을 공유하고 자원 생성과 관리 중복성을 최소화하여 수행 능력을 향상시키는 것  

## 멀티 프로그래밍
- 프로세서의 자원 낭비를 최소화하기 위해 낭비하는 시간을 다른 프로세스 수행에 쓰게 하여, 하나의 프로세서가 여러 프로세스를 교대로 수행할 수 있게 하는 것

## 멀티 스레드
#### 장점
- 적은 메모리 공간과 시스템 자원 사용으로 시스템의 throughput 향상 (응답시간 단축)  
- 스레드간 통신은 전역 변수의 공간 또는 힙 영역을 통해 데이터 교환 가능. 프로세스간 통신에 비해 방법이 간단  
- 문맥 교환시 캐시메모리를 비울 필요가 없기에 프로세스 문맥 교환에 비해 빠름  

#### 단점
- 공유 자원에 대한 처리 (동기화 작업)  
- 과도한 락으로 인한 병목 현상으로 인해 성능이 저하될 가능성 주의  

#### vs 멀티 프로세스
- 적은 메모리 공간을 차지하고 문맥 전환이 빠르다는 장점  
- 하나의 스레드가 종료되면 전체 스레드가 종료될 수 있다는 위험성 (프로세스는 죽더라도 다른 프로세스에 영향 x)  
- 동기화 문제  
- 대상 시스템의 특징에 따라 적합한 동작 방식 선택 필요  

## CPU 스케줄링
- 멀티 프로그래밍을 가능하게 하는 운영체제의 동작 기법
- "어떻게 프로세스들이 CPU를 효율적으로 사용하게 할 것인가?"

#### 선점형 스케줄링 비선점형 스케줄링
1. 선점형 스케줄링  
- 우선 순위가 높은 프로세스가 우선 순위가 낮은 다른 프로세스로부터 CPU를 뺏을 수 있음  
- 우선순위가 높은 프로세스를 빠르게 처리해야할 경우에 유용  
- 컨텍스트 스위칭으로 인한 오버헤드가 발생, 처리시간을 예측하기 힘들다는 단점  

2. 비선점형 스케줄링
- 프로세스가 CPU를 점유하고 있다면 빼앗을 수 없는 방식  
- 필요한 문맥 교환만 일어나기 때문에 오버헤드가 상대적으로 적음 (프로세스의 배치에 따라 효율성 차이 발생)  
- 병목 현상으로 인해 성능이 저하될 가능성 주의  

## CPU 스케줄링 알고리즘
#### 선점형 스케줄링  
- SRT, Round Robin, 다단계 큐, 다단계 피드백 큐  

1. SRT(Shortest Remaining Time) 
- 남은 처리 시간이 짧은 프로세스가 먼저 수행되는 방식
- 남은 시간이 더 짧은 프로세스가 Ready 큐에 들어오면 해당 프로세스가 CPU를 빼앗아 수행
- 평균 대기 시간이 가장 짧은 알고리즘
- 잦은 문맥 교환으로 인한 오버헤드와 starvation 발생 가능

2. Round Robin
- 각 프로세스에게 동일한 CPU 할당 시간을 부여. 해당 시간동안만 CPU를 이용하는 방식  
- 모든 프로세스가 최초 응답 시간을 빠르게 보장받을 수 있는 장점  
- 할당 시간이 너무 크면 FCFS(선입선출)과 다를 바가 없어지며, 너무 작으면 문맥 교환으로 인한 오버헤드가 커짐    

3. 다단계 큐
- 다단계 큐는 Ready큐를 여러 개 사용하는 기법입니다  
- 각각의 큐는 자신의 스케줄링 알고리즘을 수행  
- 큐와 큐 사이에도 우선순위를 부여  

4. 다단계 피드백 큐 
- 다단계 피드백 큐는 다단계 큐의 공평성 문제를 완화하기 위해 신분 하락이 가능한 방식  
- 우선순위가 변동되기 때문에 큐 사이의 이동이 가능  


#### 비선점형 스케줄링  
- FCFS(선입선출), HRN, SJF, 우선순위 스케줄링  

1. FCFS (First Come First Served)
- 선입선출 방식  
- 단순하고 공평  
- CPU 처리 시간이 긴 프로세스가 앞에 올 경우 뒤의 프로세스가 오래 기다려야 하기 때문에 비효율적  

2. HRN (Highest Response Ratio Next)
- "우선순위 = (대기시간+서비스시간)/서비스시간"  
- 수행시간의 길이와 대기 시간을 모두 고려해 우선순위를 정하는 방식  
- 긴 작업과 짧은 작업간의 지나친 불평등을 어느 정도 보완한 기법   

3. SJF(Shortest Job First)
- 큐 안에 있는 프로세스 중 수행시간이 짧은 것을 먼저 수행하는 방식   
- 평균 대기 시간을 감소  
- starvation 발생 가능  

## 동기와 비동기
#### 동기
- 작업을 요청한 후 결과가 나올 때까지 기다린 후 처리
- 해당 작업을 처리하는 동안 기존의 작업은 중단
- 요청된 작업이 CPU를 활용하지 않는 작업(예. IO)이라면 CPU 자원 낭비 심함

Synchronous vs Blocking  
- 시스템의 반환을 기다린다는 측면에서 동일하나 기다리는 동안 대기 큐에 머무는 것이 필수가 아니면 synchronous, 필수이면 blocking으로 구분하기도 한다  

Non-blocking  
- 작업을 요청했을 때 현재 가져올 수 있는 데이터를 바로 결과값으로 반환    
- 반환 이후 데이터가 업데이트 될 것이기에 클라이언트가 주기적으로 결과값을 확인할 필요  
- 동시에 여러 요청이 발생하면 CPU에 적지 않은 부담  
- Blocking시 CPU 낭비를 개선하기 위해 나온 방식  
  
#### 비동기
- Non-blocking에서처럼 클라이언트가 주기적으로 확인하는 것이 아니라 데이터 준비시 콜백 또는 이벤트를 통해 알림  

## 프로세스의 동기화
- Critical Section (임계영역): 동일한 자원을 동시에 접근하는 작업을 실행하는 코드 영역  

#### 임계영역 문제
- 프로세스들이 Critical Section을 함께 사용할 수 있는 프로토콜 설계

해결을 위한 기본조건  
1. Mutual Exclusion (상호 배제)  
- 프로세스 P1이 critical section에서 실행중이라면 다른 프로세스는 그들의 Critical Section에서 실행 불가  

2. Progress (진행)  
- 아무도 Critical Section에 있지 않은 상태에서 Critical Section에 들어가고자 하는 프로세스가 있으면 Critical Section 진입 허가  

3. Bounded Waiting (한정된 대기)  
- P1이 Critical Section에 진입 신청 후부터 받아들여질 때까지 다른 프로세스들이 Critical Section에 진입하는 회수에 제한이 있어야 함  

#### 해결책
1. Lock  
- HW 기반  
- Critical Section에 진입하는 프로세스는 Lock 획득. 빠져나올 때 Lock 반납    
- 한계: 다중처리기 환경에서는 시간적인 효율성 측면 때문에 적용 불가  

2. Semaphore  
- SW 기반  
- Counting Sempahore: 가용한 개수를 가진 자원 에 대한 접근 제어용. 자원을 사용하면 세마포가 감소, 방출하면 세마포가 증가  
- Binary semaphore: MUTEX (Mutual Exclusion). 이름 그대로 0 과 1 사이의 값만 가능하며, 다중 프로세스들 사이의 Critical Section 문제를 해결하기 위해 사용  

단점   
- Busy-waiting  
- 일반적으로 Critical Section에 진입을 시도했지만 실패한 프로세스에 대해서는 Block시킨 뒤 자리가 날 때 다시 깨우는 방식을 사용. 이 경우에는 Busy waiting x  

3. Monitor  
- 개발자의 코드를 상호배제 하게끔 만든 추상화된 데이터 형태  
- 공유자원에 접근하기 위한 키 획득과 자원 사용 후 해제를 모두 처리  
- 세마포어는 직접 키 해제와 공유자원 접근 처리가 필요  

## 교착상태 (Deadlock)
- 교착상태는 프로세스가 필요한 자원을 획득하지 못해 영구적으로 블록되어 있는 상태  

#### 발생 조건
- 상호배제: 한 순간에 한 프로세스만이 자원을 사용가능     
- 점유대기 (hold and wait): 이미 자원을 보유한 프로세스가 다른 자원을 요청하며 대기  
- 선취 불가 (non-preemptive): 프로세스에 의해 점유된 자원을 다른 프로세스가 강제적으로 빼앗을 수 없음  
- 대기 상태의 사이클 (circular wait): 두 개 이상의 프로세스가 자원 접근을 기다리는데 그 관계에 사이클이 존재  

대부분의 교착상태 방지 알고리즘은 4번 조건, 대기 상태의 사이클이 발생하는 일을 막는데 초점이 맞춰져 있음

#### 해결 방법
1. 예방   
- 운영체제 설계시 교착상태가 발생하기 위한 네 가지 조건 중에 하나를 설계 단계에서 배제  
- 자원 사용과 프로세스 수행에 비효율성을 야기  

2. 회피  
- 자원을 할당하기 전에 교착상태에 빠질 가능성이 있는지 확인  
- 빠질 가능성이 없을때만 자원을 할당  

3. 회복  
- 프로세스가 필요한 자원이 할당 가능하면 항상 할당  
- 주기적으로 교착상태가 발생했는지 검사하고 회복  

4. 무시  
- 회복과정의 성능저하가 더 심하다면 무시  
